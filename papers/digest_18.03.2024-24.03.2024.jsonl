{"title":"m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks","link_main":"https:\/\/arxiv.org\/abs\/2403.11085","date":"21.03.2024","type":"paper","topic":"Benchmarks & Environments","hashtags":null,"link_tweet":null,"link_code":"https:\/\/github.com\/RAIVNLab\/mnms","link_website":null,"link_other":{"dataset":"https:\/\/huggingface.co\/datasets\/zixianma\/mnms"},"notes":null,"reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments","link_main":"https:\/\/arxiv.org\/abs\/2403.11807","date":"18.03.2024","type":"paper","topic":"Benchmarks & Environments","hashtags":null,"link_tweet":null,"link_code":"https:\/\/github.com\/CUHK-ARISE\/GAMABench","link_website":null,"link_other":{},"notes":null,"reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"Tur[k]ingBench: A Challenge Benchmark for Web Agents","link_main":"https:\/\/arxiv.org\/abs\/2403.11905","date":"21.03.2024","type":"paper","topic":"Benchmarks & Environments","hashtags":null,"link_tweet":"https:\/\/twitter.com\/KevLXu\/status\/1771171188363985312?s=20","link_code":"https:\/\/github.com\/JHU-CLSP\/turking-bench","link_website":"https:\/\/turkingbench.github.io\/","link_other":{},"notes":null,"reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents","link_main":"https:\/\/arxiv.org\/abs\/2403.12014","date":"18.03.2024","type":"paper","topic":"Benchmarks & Environments","hashtags":null,"link_tweet":null,"link_code":"https:\/\/github.com\/aszala\/envgen","link_website":"https:\/\/envgen-llm.github.io\/","link_other":{},"notes":null,"reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"What Are Tools Anyway?\nA Survey from the Language Model Perspective","link_main":"https:\/\/zorazrw.github.io\/files\/WhatAreToolsAnyway.pdf","date":"20.03.2024","type":"paper","topic":"Tool Usage","hashtags":"survey","link_tweet":"https:\/\/twitter.com\/ZhiruoW\/status\/1770450977424064834?s=20","link_code":"https:\/\/github.com\/zorazrw\/awesome-tool-llm","link_website":null,"link_other":{},"notes":null,"reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction","link_main":"https:\/\/arxiv.org\/abs\/2403.11886","date":"18.03.2024","type":"paper","topic":"Reasoning & Planning","hashtags":null,"link_tweet":null,"link_code":"https:\/\/github.com\/cdhx\/QueryAgent","link_website":null,"link_other":{},"notes":null,"reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization","link_main":"https:\/\/arxiv.org\/abs\/2402.11453","date":"19.03.2024","type":"paper","topic":"Agents","hashtags":null,"link_tweet":null,"link_code":"https:\/\/github.com\/thunlp\/MatPlotAgent","link_website":null,"link_other":{},"notes":null,"reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"RecMind: Large Language Model Powered Agent For Recommendation","link_main":"https:\/\/arxiv.org\/abs\/2308.14296","date":"20.03.2024","type":"paper","topic":"Agents","hashtags":null,"link_tweet":null,"link_code":null,"link_website":null,"link_other":{},"notes":"Amazon, NAACL'24","reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
{"title":"Mastering Memory Tasks with World Models","link_main":"https:\/\/arxiv.org\/abs\/2403.04253","date":"07.03.2024","type":"paper","topic":"Other","hashtags":null,"link_tweet":null,"link_code":"https:\/\/github.com\/chandar-lab\/Recall2Imagine","link_website":"https:\/\/recall2imagine.github.io\/","link_other":{},"notes":"ICLR'24","reviews":null,"included_in_digest":"#1 (18.03.2024 - 24.03.2024)"}
